{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP1x4k9N6/0atVLzSX5A5K8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruv20047228/LLM/blob/main/coding_attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Coding Attention Mechanism**"
      ],
      "metadata": {
        "id": "HH3gQWvCVocw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2AMNckjVZW-"
      },
      "outputs": [],
      "source": [
        "from importlib.metadata import version\n",
        "print(\"torch version:\", version(\"torch\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "7EUAHCDtdf6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 : computation of the unormalized attention scores with query x2\n",
        "query = inputs[1]\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i,x_i in enumerate(inputs):\n",
        "  attn_scores_2[i] = torch.dot(x_i, query)\n",
        "\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "id": "TdaMtE4Vi3DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = 0\n",
        "for idx, element in enumerate(inputs[0]):\n",
        "  res += inputs[0][idx] * query[idx]\n",
        "\n",
        "  print(res)\n",
        "  print(torch.dot(inputs[0], query))"
      ],
      "metadata": {
        "id": "8r9KppLTjcrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2: Normalization of unnormalized attention scores\n",
        "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
        "\n",
        "print(\"Attention weights:\", attn_scores_2)\n",
        "print(\"Sum:\", attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "id": "rPtwrzhskW1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
        "\n",
        "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
        "\n",
        "print(\"Attention weights:\", attn_weights_2_naive)\n",
        "print(\"Sum: \", attn_weights_2_naive.sum())"
      ],
      "metadata": {
        "id": "UQ77ulSWlBSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
        "print(\"Attention weights:\", attn_weights_2)\n",
        "print(\"Sum: \", attn_weights_2.sum())"
      ],
      "metadata": {
        "id": "w60wEC7nnVLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computation of context vector z2\n",
        "query = inputs[1]\n",
        "\n",
        "context_vec_2 = torch.zeros(query.shape)\n",
        "for i,x_i in enumerate(inputs):\n",
        "  context_vec_2 += attn_weights_2[i]*x_i\n",
        "\n",
        "print(context_vec_2)\n"
      ],
      "metadata": {
        "id": "slOQGwuRnpY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Computation of attention weights and context vector**"
      ],
      "metadata": {
        "id": "DuMAv4Tzs38q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Computation of the unnormalized attention score\n",
        "attn_scores = torch.empty(6,6)\n",
        "\n",
        "for i, x_i in enumerate(inputs):\n",
        "  for j, x_j in enumerate(inputs):\n",
        "    attn_scores[i, j] = torch.dot(x_i, x_j)\n",
        "\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "id": "ccuc8ELlsvAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#same calculations as above but by matrix multiplications\n",
        "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "4soVuAJjtyge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "id": "SZm5TPDmuFaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
        "print(\"Row 2 sum:\", row_2_sum)\n",
        "\n",
        "print(\"All row sums:\", attn_weights.sum(dim=-1))"
      ],
      "metadata": {
        "id": "zb7ykjbCuUk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computation of context vector\n",
        "all_context_vecs = attn_weights @ inputs\n",
        "print(all_context_vecs)"
      ],
      "metadata": {
        "id": "ocS9Uv8kunMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Previous 2nd context vector:\", context_vec_2)"
      ],
      "metadata": {
        "id": "Y00dPj7du7WB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Computation of attention weights in original transformer architecture**"
      ],
      "metadata": {
        "id": "b74jf5bCvNCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x_2 = inputs[1]\n",
        "d_in = inputs.shape[1]\n",
        "d_out = 2\n"
      ],
      "metadata": {
        "id": "wf_DK2FCvQ0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
        "W_key = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
        "W_value = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "7nceB0Aiyazg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "\n",
        "print(query_2)"
      ],
      "metadata": {
        "id": "ji5iHxAA1QZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ W_key\n",
        "values = inputs @ W_value\n",
        "\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)"
      ],
      "metadata": {
        "id": "U73kAnId1iJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys_2 = keys[1]\n",
        "attn_score_22 = query_2.dot(keys_2)\n",
        "print(attn_score_22)"
      ],
      "metadata": {
        "id": "8aJoXc162Nux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores_2 = query_2 @ keys.T\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "id": "AvZUtqiU2ccr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we are scaling attention scores by dividing them with squre root of embedding dimension\n",
        "d_k = keys.shape[1]\n",
        "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "id": "Gnt3Tihz3C3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#final context vectos is achieved by matrix multiplication pf final attention scores\n",
        "context_vec_2 = attn_weights_2 @ values\n",
        "print(context_vec_2)"
      ],
      "metadata": {
        "id": "ZCsja6V03gfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Implementing compact self attention class**"
      ],
      "metadata": {
        "id": "4L7wnGpu3v2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn  as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out):\n",
        "    super().__init__()\n",
        "    self.W_query = nn.Parameter(torch.rand(d_in,d_out))\n",
        "    self.W_key = nn.Parameter(torch.rand(d_in,d_out))\n",
        "    self.W_value = nn.Parameter(torch.rand(d_in,d_out))\n",
        "\n",
        "  def forward(self, x):\n",
        "    keys = x @ self.W_key\n",
        "    queries = x @ self.W_query\n",
        "    values = x @ self.W_value\n",
        "\n",
        "    attn_scores = queries @ keys.T #omega\n",
        "    attn_weights = torch.softmax(\n",
        "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "    )\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n",
        "\n",
        "torch.manual_seed(123)\n",
        "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
        "print(sa_v1(inputs))\n"
      ],
      "metadata": {
        "id": "9bv-UCmB31aQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}